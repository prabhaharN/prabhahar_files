{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "f393a7d4-2e4c-4ad9-802b-74703bb9e9f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "413d1c5c-026a-4cbd-9052-fe484a2f2e92",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "folder_path = \"C:/Users/HP/Downloads/races_dataset/raw\"  \n",
    "\n",
    "file=[]\n",
    "\n",
    "\n",
    "for root, dirs, files in os.walk(folder_path):\n",
    "    # print(f\"Directory: {root}\")\n",
    "    # print(f\"Subdirectories: {dirs}\")\n",
    "    # print(f\"Files: {files}\\n\")\n",
    "    root_path=root.split('\\\\')\n",
    "    root_path='/'.join(root_path)\n",
    "    for i in files:\n",
    "        if not i.endswith('.ipynb') and not i.endswith('.DS_Store'):\n",
    "            path=f'{root_path}/{i}'\n",
    "            file.append(path)\n",
    "today_date = pd.to_datetime('today')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "3c0f7d3d-f626-4dc7-95d0-6635e100faeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dict={}\n",
    "\n",
    "for i in file :\n",
    "    if i.endswith('.csv'):\n",
    "        name=i.split('/')[-1].split('.')[0]\n",
    "        if name.startswith('lap_times_split'):\n",
    "            column_for_lap_file=['race_id','driver_id','lap','position','time','milliseconds']\n",
    "            df_dict[f'{name}_df']=pd.read_csv(i,header=None)\n",
    "            df_dict[f'{name}_df'].columns=column_for_lap_file\n",
    "        else:\n",
    "            df_dict[f'{name}_df']=pd.read_csv(i)\n",
    "    elif i.endswith('.json'):\n",
    "        try:\n",
    "            name=i.split('/')[-1].split('.')[0]\n",
    "            df_dict[f'{name}_df']=pd.read_json(i, lines=True)\n",
    "        except ValueError:\n",
    "            name=i.split('/')[-1].split('.')[0]\n",
    "            df_dict[f'{name}_df']=pd.read_json(i)\n",
    "    else:\n",
    "        print('no')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "4783dba3-40db-4d37-817f-d285733ded6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "circuits_df\n",
      "constructors_df\n",
      "drivers_df\n",
      "pit_stops_df\n",
      "races_df\n",
      "results_df\n",
      "lap_times_split_1_df\n",
      "lap_times_split_2_df\n",
      "lap_times_split_3_df\n",
      "lap_times_split_4_df\n",
      "lap_times_split_5_df\n",
      "qualifying_split_1_df\n",
      "qualifying_split_2_df\n"
     ]
    }
   ],
   "source": [
    "for i in df_dict:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "f3278a3d-4ab7-49a7-81a0-4b39f7c68e72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "enter enviroment :  development\n"
     ]
    }
   ],
   "source": [
    "df_dict={}\n",
    "\n",
    "data_source=str(input('enter enviroment : '))\n",
    "for i in file :\n",
    "    if i.endswith('.csv'):\n",
    "        name=i.split('/')[-1].split('.')[0]\n",
    "        if name.startswith('lap_times_split'):\n",
    "            column_for_lap_file=['race_id','driver_id','lap','position','time','milliseconds']\n",
    "            if f'{name[0:-8]}_df' not in df_dict:\n",
    "                df_dict[f'{name[0:-8]}_df']=pd.read_csv(i,header=None)\n",
    "                df_dict[f'{name[0:-8]}_df'].columns=column_for_lap_file\n",
    "                df_dict[f'{name[0:-8]}_df']['data_source']=data_source\n",
    "                df_dict[f'{name[0:-8]}_df']['ingestion_date']=today_date\n",
    "            else:  \n",
    "                df=pd.read_csv(i,header=None)\n",
    "                df.columns=column_for_lap_file\n",
    "                df['data_source']=data_source\n",
    "                df_dict[f'{name[0:-8]}_df']=pd.concat([df_dict[f'{name[0:-8]}_df'],df])\n",
    "                df_dict[f'{name[0:-8]}_df'].reset_index(drop=True,inplace=True) \n",
    "                df_dict[f'{name[0:-8]}_df']['ingestion_date']=today_date\n",
    "        else:\n",
    "            df_dict[f'{name}_df']=pd.read_csv(i)\n",
    "            df_dict[f'{name}_df']['data_source']=data_source\n",
    "            df_dict[f'{name}_df']['ingestion_date']=today_date\n",
    "    elif i.endswith('.json'):\n",
    "        try:\n",
    "            name=i.split('/')[-1].split('.')[0]\n",
    "            df_dict[f'{name}_df']=pd.read_json(i, lines=True)\n",
    "            df_dict[f'{name}_df']['data_source']=data_source\n",
    "            df_dict[f'{name}_df']['ingestion_date']=today_date\n",
    "        except ValueError:\n",
    "            name=i.split('/')[-1].split('.')[0]\n",
    "            if name.startswith('qualifying_split'):\n",
    "                if f'{name[0:-8]}_df' not in df_dict:\n",
    "                    df_dict[f'{name[0:-8]}_df']=pd.read_json(i)\n",
    "                    df_dict[f'{name[0:-8]}_df']['data_source']=data_source\n",
    "                    df_dict[f'{name[0:-8]}_df']['ingestion_date']=today_date\n",
    "                else:  \n",
    "                    df=pd.read_json(i)\n",
    "                    df['data_source']=data_source\n",
    "                    df_dict[f'{name[0:-8]}_df']=pd.concat([df_dict[f'{name[0:-8]}_df'],df])\n",
    "                    df_dict[f'{name[0:-8]}_df'].reset_index(drop=True,inplace=True)\n",
    "                    df_dict[f'{name[0:-8]}_df']['ingestion_date']=today_date\n",
    "                    \n",
    "            else:        \n",
    "                df_dict[f'{name}_df']=pd.read_json(i)\n",
    "                df_dict[f'{name}_df']['data_source']=data_source\n",
    "                df_dict[f'{name}_df']['ingestion_date']=today_date\n",
    "    else:\n",
    "        print('no')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "cbcb2afe-bfe7-4596-90cc-aff69391011c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for df in df_dict:\n",
    "    df = df_dict[df]\n",
    "    \n",
    "    column=list(df.columns)\n",
    "    for column_name in column:\n",
    "        if not column_name.islower() and column_name.isalpha():\n",
    "            for letter in column_name:\n",
    "                if letter.isupper():\n",
    "                    pos=column_name.index(letter)\n",
    "                    word1=column_name[0:pos]\n",
    "                    word2=column_name[pos:].lower()\n",
    "                    column_name_changed=word1+'_'+word2\n",
    "                    df.rename(columns={column_name:column_name_changed},inplace=True)\n",
    "        col_dict={'lat':'lattitude', 'lng':'longitude', 'alt':'altitude'}            \n",
    "        if column_name in ('lat', 'lng', 'alt') :\n",
    "            df.rename(columns={column_name:col_dict[column_name]},inplace=True)\n",
    "    try:\n",
    "        df.drop(columns=['url'], inplace=True)\n",
    "    except Exception as e:\n",
    "        pass        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "a0ed939b-07c8-4c7c-96f0-029c306cb238",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     driver_id         driver_ref number code          full_name         dob  \\\n",
      "0            1           hamilton     44  HAM     Lewis Hamilton  1985-01-07   \n",
      "1            2           heidfeld     \\N  HEI      Nick Heidfeld  1977-05-10   \n",
      "2            3            rosberg      6  ROS       Nico Rosberg  1985-06-27   \n",
      "3            4             alonso     14  ALO    Fernando Alonso  1981-07-29   \n",
      "4            5         kovalainen     \\N  KOV  Heikki Kovalainen  1981-10-19   \n",
      "..         ...                ...    ...  ...                ...         ...   \n",
      "848        850  pietro_fittipaldi     51  FIT  Pietro Fittipaldi  1996-06-25   \n",
      "849        851             aitken     89  AIT        Jack Aitken  1995-09-23   \n",
      "850        852            tsunoda     \\N  TSU       Yuki Tsunoda  2000-05-11   \n",
      "851        853            mazepin     \\N  MAZ     Nikita Mazepin  1999-03-02   \n",
      "852        854    mick_schumacher     \\N  SCH    Mick Schumacher  1999-03-22   \n",
      "\n",
      "    nationality  data_source             ingestion_date  \n",
      "0       British  development 2024-07-18 15:25:21.626198  \n",
      "1        German  development 2024-07-18 15:25:21.626198  \n",
      "2        German  development 2024-07-18 15:25:21.626198  \n",
      "3       Spanish  development 2024-07-18 15:25:21.626198  \n",
      "4       Finnish  development 2024-07-18 15:25:21.626198  \n",
      "..          ...          ...                        ...  \n",
      "848   Brazilian  development 2024-07-18 15:25:21.626198  \n",
      "849     British  development 2024-07-18 15:25:21.626198  \n",
      "850    Japanese  development 2024-07-18 15:25:21.626198  \n",
      "851     Russian  development 2024-07-18 15:25:21.626198  \n",
      "852      German  development 2024-07-18 15:25:21.626198  \n",
      "\n",
      "[853 rows x 9 columns]\n"
     ]
    }
   ],
   "source": [
    "from unidecode import unidecode\n",
    "for i in df_dict:\n",
    "    if i=='drivers_df':\n",
    "        df=df_dict[i]\n",
    "        names=df['name']\n",
    "        full_name=[]\n",
    "        for name in names:\n",
    "            full_name.append(unidecode(name['forename'])+' '+unidecode(name['surname']))\n",
    "        df.insert(4,'full_name',value=full_name)\n",
    "        df.drop(columns=['name'],inplace =True)\n",
    "\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ef9dfa7-4a5f-4880-b3f0-2113e3a6846c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "ef4136a1-9024-4e55-8a87-8b85410f2c59",
   "metadata": {},
   "outputs": [],
   "source": [
    "lap_times_df=pd.DataFrame()\n",
    "qualifying_df=pd.DataFrame()\n",
    "for i in df_dict :\n",
    "    if i.startswith('lap_times_split'):\n",
    "        lap_times_df=pd.concat([lap_times_df,df_dict[i]])\n",
    "        lap_times_df .reset_index(drop=True) \n",
    "    elif i.startswith('qualifying_split'):\n",
    "        qualifying_df=pd.concat([qualifying_df,df_dict[i]])\n",
    "        qualifying_df .reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "ca0d2941-05b6-44bb-910f-48edfd93c4d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "circuits_df\n",
      "constructors_df\n",
      "drivers_df\n",
      "pit_stops_df\n",
      "races_df\n",
      "results_df\n",
      "lap_times_df\n",
      "qualifying_df\n"
     ]
    }
   ],
   "source": [
    "for i in df_dict:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "e495eacd-8e67-473f-8c8a-1e1b5ea664eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_dict['circuits_df']\n",
    "df.to_parquet('circuits____________________df',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "c77ec1f9-0cc7-4642-b546-e9fb449a5aa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_dict['constructors_df']\n",
    "df.to_parquet('constructors____________________df',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "c63c922e-8610-4a80-8677-d270b55d5d94",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df = df_dict['drivers_df']\n",
    "def convert_to_null(val):\n",
    "    if isinstance(val, str):\n",
    "        return np.nan\n",
    "    return val\n",
    "df['number'] = df['number'].apply(convert_to_null)\n",
    "\n",
    "df.to_parquet('drive____________________df',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "2ec73c83-1b1e-4dec-ad40-64369d48796e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_dict['pit_stops_df']\n",
    "df.fillna(np.nan,inplace=True)\n",
    "df['duration']=df['duration'].astype('str')\n",
    "df.to_parquet('pit_stops____________________df',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "2d9db990-27db-4ef3-99a6-118669888dde",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_dict['races_df']\n",
    "df.to_parquet('races____________________df',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "2adac427-899d-4d5d-ba08-9b93dda5e74e",
   "metadata": {},
   "outputs": [
    {
     "ename": "ArrowInvalid",
     "evalue": "(\"Could not convert 'R' with type str: tried to convert to int64\", 'Conversion failed for column position_text with type object')",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mArrowInvalid\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[229], line 7\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m val\n\u001b[0;32m      6\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mposition\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mposition\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(convert_to_null)\n\u001b[1;32m----> 7\u001b[0m df\u001b[38;5;241m.\u001b[39mto_parquet(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mresults____________________df\u001b[39m\u001b[38;5;124m'\u001b[39m,index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\frame.py:2970\u001b[0m, in \u001b[0;36mDataFrame.to_parquet\u001b[1;34m(self, path, engine, compression, index, partition_cols, storage_options, **kwargs)\u001b[0m\n\u001b[0;32m   2882\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   2883\u001b[0m \u001b[38;5;124;03mWrite a DataFrame to the binary parquet format.\u001b[39;00m\n\u001b[0;32m   2884\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2966\u001b[0m \u001b[38;5;124;03m>>> content = f.read()\u001b[39;00m\n\u001b[0;32m   2967\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   2968\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mio\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mparquet\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m to_parquet\n\u001b[1;32m-> 2970\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m to_parquet(\n\u001b[0;32m   2971\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   2972\u001b[0m     path,\n\u001b[0;32m   2973\u001b[0m     engine,\n\u001b[0;32m   2974\u001b[0m     compression\u001b[38;5;241m=\u001b[39mcompression,\n\u001b[0;32m   2975\u001b[0m     index\u001b[38;5;241m=\u001b[39mindex,\n\u001b[0;32m   2976\u001b[0m     partition_cols\u001b[38;5;241m=\u001b[39mpartition_cols,\n\u001b[0;32m   2977\u001b[0m     storage_options\u001b[38;5;241m=\u001b[39mstorage_options,\n\u001b[0;32m   2978\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m   2979\u001b[0m )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\parquet.py:483\u001b[0m, in \u001b[0;36mto_parquet\u001b[1;34m(df, path, engine, compression, index, storage_options, partition_cols, filesystem, **kwargs)\u001b[0m\n\u001b[0;32m    479\u001b[0m impl \u001b[38;5;241m=\u001b[39m get_engine(engine)\n\u001b[0;32m    481\u001b[0m path_or_buf: FilePath \u001b[38;5;241m|\u001b[39m WriteBuffer[\u001b[38;5;28mbytes\u001b[39m] \u001b[38;5;241m=\u001b[39m io\u001b[38;5;241m.\u001b[39mBytesIO() \u001b[38;5;28;01mif\u001b[39;00m path \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m path\n\u001b[1;32m--> 483\u001b[0m impl\u001b[38;5;241m.\u001b[39mwrite(\n\u001b[0;32m    484\u001b[0m     df,\n\u001b[0;32m    485\u001b[0m     path_or_buf,\n\u001b[0;32m    486\u001b[0m     compression\u001b[38;5;241m=\u001b[39mcompression,\n\u001b[0;32m    487\u001b[0m     index\u001b[38;5;241m=\u001b[39mindex,\n\u001b[0;32m    488\u001b[0m     partition_cols\u001b[38;5;241m=\u001b[39mpartition_cols,\n\u001b[0;32m    489\u001b[0m     storage_options\u001b[38;5;241m=\u001b[39mstorage_options,\n\u001b[0;32m    490\u001b[0m     filesystem\u001b[38;5;241m=\u001b[39mfilesystem,\n\u001b[0;32m    491\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m    492\u001b[0m )\n\u001b[0;32m    494\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m path \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    495\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(path_or_buf, io\u001b[38;5;241m.\u001b[39mBytesIO)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\parquet.py:189\u001b[0m, in \u001b[0;36mPyArrowImpl.write\u001b[1;34m(self, df, path, compression, index, storage_options, partition_cols, filesystem, **kwargs)\u001b[0m\n\u001b[0;32m    186\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m index \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    187\u001b[0m     from_pandas_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpreserve_index\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m index\n\u001b[1;32m--> 189\u001b[0m table \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapi\u001b[38;5;241m.\u001b[39mTable\u001b[38;5;241m.\u001b[39mfrom_pandas(df, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfrom_pandas_kwargs)\n\u001b[0;32m    191\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m df\u001b[38;5;241m.\u001b[39mattrs:\n\u001b[0;32m    192\u001b[0m     df_metadata \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPANDAS_ATTRS\u001b[39m\u001b[38;5;124m\"\u001b[39m: json\u001b[38;5;241m.\u001b[39mdumps(df\u001b[38;5;241m.\u001b[39mattrs)}\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pyarrow\\table.pxi:3869\u001b[0m, in \u001b[0;36mpyarrow.lib.Table.from_pandas\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pyarrow\\pandas_compat.py:626\u001b[0m, in \u001b[0;36mdataframe_to_arrays\u001b[1;34m(df, schema, preserve_index, nthreads, columns, safe)\u001b[0m\n\u001b[0;32m    624\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i, maybe_fut \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(arrays):\n\u001b[0;32m    625\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(maybe_fut, futures\u001b[38;5;241m.\u001b[39mFuture):\n\u001b[1;32m--> 626\u001b[0m             arrays[i] \u001b[38;5;241m=\u001b[39m maybe_fut\u001b[38;5;241m.\u001b[39mresult()\n\u001b[0;32m    628\u001b[0m types \u001b[38;5;241m=\u001b[39m [x\u001b[38;5;241m.\u001b[39mtype \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m arrays]\n\u001b[0;32m    630\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m schema \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\concurrent\\futures\\_base.py:449\u001b[0m, in \u001b[0;36mFuture.result\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    447\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CancelledError()\n\u001b[0;32m    448\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;241m==\u001b[39m FINISHED:\n\u001b[1;32m--> 449\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__get_result()\n\u001b[0;32m    451\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_condition\u001b[38;5;241m.\u001b[39mwait(timeout)\n\u001b[0;32m    453\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;129;01min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\concurrent\\futures\\_base.py:401\u001b[0m, in \u001b[0;36mFuture.__get_result\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    399\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception:\n\u001b[0;32m    400\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 401\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception\n\u001b[0;32m    402\u001b[0m     \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    403\u001b[0m         \u001b[38;5;66;03m# Break a reference cycle with the exception in self._exception\u001b[39;00m\n\u001b[0;32m    404\u001b[0m         \u001b[38;5;28mself\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\concurrent\\futures\\thread.py:58\u001b[0m, in \u001b[0;36m_WorkItem.run\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     55\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m     57\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 58\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfn(\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkwargs)\n\u001b[0;32m     59\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[0;32m     60\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfuture\u001b[38;5;241m.\u001b[39mset_exception(exc)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pyarrow\\pandas_compat.py:600\u001b[0m, in \u001b[0;36mdataframe_to_arrays.<locals>.convert_column\u001b[1;34m(col, field)\u001b[0m\n\u001b[0;32m    595\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (pa\u001b[38;5;241m.\u001b[39mArrowInvalid,\n\u001b[0;32m    596\u001b[0m         pa\u001b[38;5;241m.\u001b[39mArrowNotImplementedError,\n\u001b[0;32m    597\u001b[0m         pa\u001b[38;5;241m.\u001b[39mArrowTypeError) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    598\u001b[0m     e\u001b[38;5;241m.\u001b[39margs \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConversion failed for column \u001b[39m\u001b[38;5;132;01m{!s}\u001b[39;00m\u001b[38;5;124m with type \u001b[39m\u001b[38;5;132;01m{!s}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    599\u001b[0m                \u001b[38;5;241m.\u001b[39mformat(col\u001b[38;5;241m.\u001b[39mname, col\u001b[38;5;241m.\u001b[39mdtype),)\n\u001b[1;32m--> 600\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[0;32m    601\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m field_nullable \u001b[38;5;129;01mand\u001b[39;00m result\u001b[38;5;241m.\u001b[39mnull_count \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m    602\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mField \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m was non-nullable but pandas column \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    603\u001b[0m                      \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhad \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m null values\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;28mstr\u001b[39m(field),\n\u001b[0;32m    604\u001b[0m                                                  result\u001b[38;5;241m.\u001b[39mnull_count))\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pyarrow\\pandas_compat.py:594\u001b[0m, in \u001b[0;36mdataframe_to_arrays.<locals>.convert_column\u001b[1;34m(col, field)\u001b[0m\n\u001b[0;32m    591\u001b[0m     type_ \u001b[38;5;241m=\u001b[39m field\u001b[38;5;241m.\u001b[39mtype\n\u001b[0;32m    593\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 594\u001b[0m     result \u001b[38;5;241m=\u001b[39m pa\u001b[38;5;241m.\u001b[39marray(col, \u001b[38;5;28mtype\u001b[39m\u001b[38;5;241m=\u001b[39mtype_, from_pandas\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, safe\u001b[38;5;241m=\u001b[39msafe)\n\u001b[0;32m    595\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (pa\u001b[38;5;241m.\u001b[39mArrowInvalid,\n\u001b[0;32m    596\u001b[0m         pa\u001b[38;5;241m.\u001b[39mArrowNotImplementedError,\n\u001b[0;32m    597\u001b[0m         pa\u001b[38;5;241m.\u001b[39mArrowTypeError) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    598\u001b[0m     e\u001b[38;5;241m.\u001b[39margs \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConversion failed for column \u001b[39m\u001b[38;5;132;01m{!s}\u001b[39;00m\u001b[38;5;124m with type \u001b[39m\u001b[38;5;132;01m{!s}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    599\u001b[0m                \u001b[38;5;241m.\u001b[39mformat(col\u001b[38;5;241m.\u001b[39mname, col\u001b[38;5;241m.\u001b[39mdtype),)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pyarrow\\array.pxi:340\u001b[0m, in \u001b[0;36mpyarrow.lib.array\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pyarrow\\array.pxi:86\u001b[0m, in \u001b[0;36mpyarrow.lib._ndarray_to_array\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pyarrow\\error.pxi:91\u001b[0m, in \u001b[0;36mpyarrow.lib.check_status\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mArrowInvalid\u001b[0m: (\"Could not convert 'R' with type str: tried to convert to int64\", 'Conversion failed for column position_text with type object')"
     ]
    }
   ],
   "source": [
    "df = df_dict['results_df']\n",
    "df['number'] = df['number'].apply(convert_to_null)\n",
    "df.to_parquet('results____________________df',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "d7c43366-fe63-4e79-83d8-6b307ce53a79",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.int64"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "b43077fa-863c-4232-b3ae-80b0dd944c8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raikkonen\n"
     ]
    }
   ],
   "source": [
    "from unidecode import unidecode\n",
    "\n",
    "original_name = 'Räikkönen'\n",
    "converted_name = unidecode(original_name)\n",
    "\n",
    "print(converted_name) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "ddb45c7a-69d8-48b0-800f-34d6151ba7f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_parquet_df = pd.read_parquet('drive____________________df')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "88f7fb73-50f8-4ea3-88f6-34318f94aac1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>driver_id</th>\n",
       "      <th>driver_ref</th>\n",
       "      <th>number</th>\n",
       "      <th>code</th>\n",
       "      <th>full_name</th>\n",
       "      <th>dob</th>\n",
       "      <th>nationality</th>\n",
       "      <th>data_source</th>\n",
       "      <th>ingestion_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>hamilton</td>\n",
       "      <td>44</td>\n",
       "      <td>HAM</td>\n",
       "      <td>Lewis Hamilton</td>\n",
       "      <td>1985-01-07</td>\n",
       "      <td>British</td>\n",
       "      <td>development</td>\n",
       "      <td>2024-07-18 15:25:21.626198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>heidfeld</td>\n",
       "      <td>0</td>\n",
       "      <td>HEI</td>\n",
       "      <td>Nick Heidfeld</td>\n",
       "      <td>1977-05-10</td>\n",
       "      <td>German</td>\n",
       "      <td>development</td>\n",
       "      <td>2024-07-18 15:25:21.626198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>rosberg</td>\n",
       "      <td>6</td>\n",
       "      <td>ROS</td>\n",
       "      <td>Nico Rosberg</td>\n",
       "      <td>1985-06-27</td>\n",
       "      <td>German</td>\n",
       "      <td>development</td>\n",
       "      <td>2024-07-18 15:25:21.626198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>alonso</td>\n",
       "      <td>14</td>\n",
       "      <td>ALO</td>\n",
       "      <td>Fernando Alonso</td>\n",
       "      <td>1981-07-29</td>\n",
       "      <td>Spanish</td>\n",
       "      <td>development</td>\n",
       "      <td>2024-07-18 15:25:21.626198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>kovalainen</td>\n",
       "      <td>0</td>\n",
       "      <td>KOV</td>\n",
       "      <td>Heikki Kovalainen</td>\n",
       "      <td>1981-10-19</td>\n",
       "      <td>Finnish</td>\n",
       "      <td>development</td>\n",
       "      <td>2024-07-18 15:25:21.626198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>848</th>\n",
       "      <td>850</td>\n",
       "      <td>pietro_fittipaldi</td>\n",
       "      <td>51</td>\n",
       "      <td>FIT</td>\n",
       "      <td>Pietro Fittipaldi</td>\n",
       "      <td>1996-06-25</td>\n",
       "      <td>Brazilian</td>\n",
       "      <td>development</td>\n",
       "      <td>2024-07-18 15:25:21.626198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>849</th>\n",
       "      <td>851</td>\n",
       "      <td>aitken</td>\n",
       "      <td>89</td>\n",
       "      <td>AIT</td>\n",
       "      <td>Jack Aitken</td>\n",
       "      <td>1995-09-23</td>\n",
       "      <td>British</td>\n",
       "      <td>development</td>\n",
       "      <td>2024-07-18 15:25:21.626198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>850</th>\n",
       "      <td>852</td>\n",
       "      <td>tsunoda</td>\n",
       "      <td>0</td>\n",
       "      <td>TSU</td>\n",
       "      <td>Yuki Tsunoda</td>\n",
       "      <td>2000-05-11</td>\n",
       "      <td>Japanese</td>\n",
       "      <td>development</td>\n",
       "      <td>2024-07-18 15:25:21.626198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>851</th>\n",
       "      <td>853</td>\n",
       "      <td>mazepin</td>\n",
       "      <td>0</td>\n",
       "      <td>MAZ</td>\n",
       "      <td>Nikita Mazepin</td>\n",
       "      <td>1999-03-02</td>\n",
       "      <td>Russian</td>\n",
       "      <td>development</td>\n",
       "      <td>2024-07-18 15:25:21.626198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>852</th>\n",
       "      <td>854</td>\n",
       "      <td>mick_schumacher</td>\n",
       "      <td>0</td>\n",
       "      <td>SCH</td>\n",
       "      <td>Mick Schumacher</td>\n",
       "      <td>1999-03-22</td>\n",
       "      <td>German</td>\n",
       "      <td>development</td>\n",
       "      <td>2024-07-18 15:25:21.626198</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>853 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     driver_id         driver_ref  number code          full_name         dob  \\\n",
       "0            1           hamilton      44  HAM     Lewis Hamilton  1985-01-07   \n",
       "1            2           heidfeld       0  HEI      Nick Heidfeld  1977-05-10   \n",
       "2            3            rosberg       6  ROS       Nico Rosberg  1985-06-27   \n",
       "3            4             alonso      14  ALO    Fernando Alonso  1981-07-29   \n",
       "4            5         kovalainen       0  KOV  Heikki Kovalainen  1981-10-19   \n",
       "..         ...                ...     ...  ...                ...         ...   \n",
       "848        850  pietro_fittipaldi      51  FIT  Pietro Fittipaldi  1996-06-25   \n",
       "849        851             aitken      89  AIT        Jack Aitken  1995-09-23   \n",
       "850        852            tsunoda       0  TSU       Yuki Tsunoda  2000-05-11   \n",
       "851        853            mazepin       0  MAZ     Nikita Mazepin  1999-03-02   \n",
       "852        854    mick_schumacher       0  SCH    Mick Schumacher  1999-03-22   \n",
       "\n",
       "    nationality  data_source             ingestion_date  \n",
       "0       British  development 2024-07-18 15:25:21.626198  \n",
       "1        German  development 2024-07-18 15:25:21.626198  \n",
       "2        German  development 2024-07-18 15:25:21.626198  \n",
       "3       Spanish  development 2024-07-18 15:25:21.626198  \n",
       "4       Finnish  development 2024-07-18 15:25:21.626198  \n",
       "..          ...          ...                        ...  \n",
       "848   Brazilian  development 2024-07-18 15:25:21.626198  \n",
       "849     British  development 2024-07-18 15:25:21.626198  \n",
       "850    Japanese  development 2024-07-18 15:25:21.626198  \n",
       "851     Russian  development 2024-07-18 15:25:21.626198  \n",
       "852      German  development 2024-07-18 15:25:21.626198  \n",
       "\n",
       "[853 rows x 9 columns]"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "474f6660-aaa0-4cc9-8b50-637e52807221",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
